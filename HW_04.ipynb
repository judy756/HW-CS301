{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Judy Zuo\n",
    "# Date: 2020 02 14\n",
    "# CS301-006, Professor Watson\n",
    "# HW03 Solution\n",
    "# methods to read data from file, find the number of outliers and find the std\n",
    "# link to the git repo :   https://github.com/judy756/HW-CS301\n",
    "# link-to-the-relevant-git-commit \n",
    "#      https://github.com/judy756/HW-CS301/commit/c6efdc15736cce26dd98feb62d7a12f3bcf0e761\n",
    "# name-of-the-branch : master\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percent_nans(df, column_name):\n",
    "    #df = pd.DataFrame(df);\n",
    "    total = df.shape[0];\n",
    "    empty = df.loc[df[column_name].isna()];\n",
    "    \n",
    "    return (empty.shape[0]/total) * 100;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Province/State\" column has 24.45% empty values\n",
      "The \"Country/Region\" column has 0.00% empty values\n",
      "The \"Last Update\" column has 0.00% empty values\n",
      "The \"Confirmed\" column has 1.60% empty values\n",
      "The \"Suspected\" column has 95.31% empty values\n",
      "The \"Recovered\" column has 46.67% empty values\n",
      "The \"Death\" column has 53.22% empty values\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'C:\\\\Users\\\\judyz\\\\OneDrive\\\\Documents'\n",
    "file_name = data_dir + '\\\\2019_nCoV_20200121_20200206.csv'\n",
    "my_df = pd.read_csv(file_name)\n",
    "for col in my_df.columns:\n",
    "    print('The \\\"{}\\\" column has {:.2f}% empty values'.format(col, get_percent_nans(my_df, col)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Mainland China\n",
       "70    Mainland China\n",
       "Name: Country/Region, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Country/Region with most death\n",
    "\n",
    "my_df.loc[my_df['Death'] == my_df['Death'].max()]['Country/Region']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1532    Hong Kong\n",
       "1581    Hong Kong\n",
       "1623    Hong Kong\n",
       "Name: Country/Region, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find Country/Region with highest number of suspected or max in suspected\n",
    "\n",
    "my_df.loc[my_df['Suspected'] == my_df['Suspected'].max()]['Country/Region']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mainland China'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find Country/Region with second highest number of recovered\n",
    "\n",
    "sorted_df = my_df.sort_values('Recovered')\n",
    "sorted_df = sorted_df.reset_index()\n",
    "\n",
    "sorted_df.loc[sorted_df['Recovered'].idxmax()-1]['Country/Region']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continent(country):\n",
    "    dic = {'Mainland China': 'Asia', 'Singapore': 'Asia', \n",
    "       'Thailand': 'Asia', 'Japan': 'Asia', \n",
    "       'Hong Kong': 'Asia', 'South Korea': 'Asia', \n",
    "       'Germany': 'Europe', 'Malaysia': 'Asia', \n",
    "       'Taiwan': 'Asia', 'Macau': 'Asia', \n",
    "       'Vietnam': 'Asia', 'France': 'Europe', \n",
    "       'United Arab Emirates': 'Asia', 'Australia':'Australia', \n",
    "       'India': 'Asia', 'Canada': 'North America', \n",
    "       'Italy': 'Europe', 'Philippines': 'Asia', \n",
    "       'Russia': 'Asia', 'UK': 'Europe', \n",
    "       'United States': 'North America', 'Belgium': 'Europe', \n",
    "       'Cambodia': 'Asia', 'Finland': 'Europe', \n",
    "       'Nepal': 'Asia', 'Spain': 'Europe', \n",
    "       'Sri Lanka': 'Asia', 'Sweden': 'Europe', \n",
    "       'Ivory Coast': 'Africa', 'Mexico': 'North America', \n",
    "       'Brazil': 'South America', 'Colombia': 'South America'};\n",
    "    \n",
    "    return dic[country];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe\n"
     ]
    }
   ],
   "source": [
    "print(get_continent('UK'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Suspected</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Death</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 16:43</td>\n",
       "      <td>16678.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>538.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 13:23</td>\n",
       "      <td>895.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Zhejiang</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:13</td>\n",
       "      <td>895.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Henan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:03</td>\n",
       "      <td>764.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Hunan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:23</td>\n",
       "      <td>661.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1872</td>\n",
       "      <td>Heilongjiang</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1876</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Province/State  Country/Region   Last Update  Confirmed  Suspected  \\\n",
       "0             Hubei  Mainland China  2/5/20 16:43    16678.0        NaN   \n",
       "1         Guangdong  Mainland China  2/5/20 13:23      895.0        NaN   \n",
       "2          Zhejiang  Mainland China  2/5/20 15:13      895.0        NaN   \n",
       "3             Henan  Mainland China  2/5/20 15:03      764.0        NaN   \n",
       "4             Hunan  Mainland China  2/5/20 15:23      661.0        NaN   \n",
       "...             ...             ...           ...        ...        ...   \n",
       "1872   Heilongjiang  Mainland China     1/21/2020        NaN        1.0   \n",
       "1873            NaN           Japan     1/21/2020        1.0        NaN   \n",
       "1874            NaN        Thailand     1/21/2020        2.0        NaN   \n",
       "1875            NaN     South Korea     1/21/2020        1.0        NaN   \n",
       "1876     Washington   United States     1/21/2020        1.0        NaN   \n",
       "\n",
       "      Recovered  Death      Continent  \n",
       "0         538.0  479.0           Asia  \n",
       "1          49.0    0.0           Asia  \n",
       "2          78.0    0.0           Asia  \n",
       "3          47.0    2.0           Asia  \n",
       "4          54.0    0.0           Asia  \n",
       "...         ...    ...            ...  \n",
       "1872        NaN    NaN           Asia  \n",
       "1873        NaN    NaN           Asia  \n",
       "1874        NaN    NaN           Asia  \n",
       "1875        NaN    NaN           Asia  \n",
       "1876        NaN    NaN  North America  \n",
       "\n",
       "[1877 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add column 'Continent'\n",
    "\n",
    "for i in range(my_df.shape[0]):\n",
    "    my_df.loc[i, 'Continent'] = get_continent(my_df.loc[i,'Country/Region'])\n",
    "\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of confirmed cases in Asia is 304984.0\n",
      "The total number of confirmed cases in Europe is 395.0\n",
      "The total number of confirmed cases in Australia is 238.0\n",
      "The total number of confirmed cases in North America is 273.0\n",
      "The total number of confirmed cases in Africa is 1.0\n",
      "The total number of confirmed cases in South America is 0.0\n"
     ]
    }
   ],
   "source": [
    "#Total number of confirmed cases in each continent\n",
    "\n",
    "con_groups = my_df.groupby('Continent')\n",
    "for con in my_df['Continent'].unique():\n",
    "    print('The total number of confirmed cases in {} is {}'.format(con, con_groups.get_group(con)['Confirmed'].sum()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
